{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting course evaluations with Decision Trees\n",
    "\n",
    "\n",
    "## 1. ID3 Algorithm Implementation\n",
    "\n",
    "### 1.1. Tree data structure and helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionNode:\n",
    "    def __init__(self, col=-1, value=None, results=None, tb=None, fb=None):\n",
    "        self.col = col # attribute on which to split\n",
    "        self.value = value # value on which to split\n",
    "        self.results = results # If the node has no children - we store here class labels with their counts\n",
    "        self.tb = tb  # True branch\n",
    "        self.fb = fb  # False branch\n",
    "        \n",
    "def split(rows, column, value):\n",
    "    # define split function according to the value type\n",
    "    split_function = None\n",
    "    if isinstance(value, int) or isinstance(value, float):\n",
    "        split_function = lambda row: row[column] >= value\n",
    "    else:\n",
    "        split_function = lambda row: row[column] == value\n",
    "\n",
    "    # Divide the rows into two sets and return them\n",
    "    set1 = [row for row in rows if split_function(row)]\n",
    "    set2 = [row for row in rows if not split_function(row)]\n",
    "    return (set1, set2)\n",
    "\n",
    "def count_labels(rows):\n",
    "    label_count = {}\n",
    "    for row in rows:\n",
    "        # The class label is in the last column\n",
    "        label = row[- 1]\n",
    "        if label not in label_count:\n",
    "            label_count[label] = 0\n",
    "        label_count[label] += 1\n",
    "    return label_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Node purity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "def gini_impurity(rows):\n",
    "    total = len(rows)\n",
    "    counts = count_labels(rows)\n",
    "    gini = 0\n",
    "    for key, val in counts.items():\n",
    "        p = val / total\n",
    "        gini += p*p\n",
    "        \n",
    "    return (1 - gini)\n",
    "\n",
    "def entropy(rows):\n",
    "    total = len(rows)\n",
    "    counts = count_labels(rows)\n",
    "    ent = 0.0\n",
    "    for key,val in counts.items():\n",
    "        p = val / total\n",
    "        ent = ent - p * log(p, 2)\n",
    "    return ent\n",
    "\n",
    "\n",
    "def variance(rows):\n",
    "    if len(rows) == 0: return 0\n",
    "    num_label = [float(row[- 1]) for row in rows]\n",
    "    mean = sum(num_label) / len(num_label)\n",
    "    variance = sum([(d - mean) ** 2 for d in num_label]) / len(num_label)\n",
    "    return variance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Tree induction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildtree(rows, score_func=entropy, min_improvement=0, min_samples=0, max_depth=None, depth=0):\n",
    "    if len(rows) == 0:\n",
    "        return DecisionNode()\n",
    "    # Compute overall score for the entire rows dataset\n",
    "    current_score = score_func(rows)\n",
    "\n",
    "    # Set up accumulator variables to track the best split criteria\n",
    "    best_score = current_score\n",
    "    best_criteria = None\n",
    "    best_sets = None\n",
    "    \n",
    "    # Total number of features - except the last column where we store the class (target)\n",
    "    column_count = len(rows[0]) - 1 \n",
    "    for col in range(0, column_count):\n",
    "        # Generate the list of unique values in\n",
    "        # this column to split on them\n",
    "        column_values = set()\n",
    "        for row in rows:\n",
    "            column_values.add(row[col])\n",
    "            \n",
    "        # Now try splitting the rows \n",
    "        # on each unique value in this column\n",
    "        for value in column_values:\n",
    "            (set1, set2) = split(rows, col, value)\n",
    "\n",
    "            # Evaluate the quality of the split\n",
    "            # p is the proportion of subset set1 \n",
    "            p = float(len(set1)) / len(rows)\n",
    "            split_score = p * score_func(set1) + (1-p) * score_func(set2)\n",
    "            \n",
    "            if split_score < best_score and \\\n",
    "                (len(set1) > min_samples and len(set2) > min_samples) and \\\n",
    "                (current_score - split_score) > min_improvement:\n",
    "                best_score = split_score\n",
    "                best_criteria = (col, value)\n",
    "                best_sets = (set1, set2)\n",
    "\n",
    "    # Create the sub branches\n",
    "    if (current_score - best_score) > min_improvement and \\\n",
    "        (max_depth is None or depth < max_depth) :\n",
    "        # print(\"Splitting on\",best_criteria, \" 2 sets:\", len(best_sets[0]),len(best_sets[1]))\n",
    "        true_branch = buildtree(best_sets[0], score_func, min_improvement, min_samples, max_depth, depth+1)\n",
    "        false_branch = buildtree(best_sets[1], score_func, min_improvement, min_samples, max_depth, depth+1)\n",
    "        return DecisionNode(col=best_criteria[0], value=best_criteria[1],\n",
    "                            tb=true_branch, fb=false_branch)\n",
    "    else: # Done splitting - summarize class labels in leaf nodes\n",
    "        return DecisionNode(results=count_labels(rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Tree printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(leaf_labels):\n",
    "    total = 0\n",
    "    result = {}\n",
    "    for label, count in leaf_labels.items():\n",
    "        total += count\n",
    "        result[label] = count\n",
    "\n",
    "    for label, val in result.items():\n",
    "        result[label] = str(int(result[label]/total * 100))+\"%\"\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(tree, current_branch, attributes=None,  indent='', leaf_funct=prediction):\n",
    "    # Is this a leaf node?\n",
    "    if tree.results != None:\n",
    "        print(indent + current_branch + str(leaf_funct(tree.results)))\n",
    "    else:\n",
    "        # Print the split question\n",
    "        split_col = str(tree.col)\n",
    "        if attributes is not None:\n",
    "            split_col = attributes[tree.col]\n",
    "        split_val = str(tree.value)\n",
    "        if type(tree.value) == int or type(tree.value) == float:\n",
    "            split_val = \">=\" + str(tree.value)\n",
    "        print(indent + current_branch + split_col + ': ' + split_val + '? ')\n",
    "\n",
    "        # Print the branches\n",
    "        indent = indent + '  '\n",
    "        print_tree(tree.tb, 'T->', attributes, indent)\n",
    "        print_tree(tree.fb, 'F->', attributes, indent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(observation, tree):\n",
    "    if tree.results != None:\n",
    "        return prediction(tree.results)\n",
    "    else:\n",
    "        v = observation[tree.col]\n",
    "        branch = None\n",
    "        if isinstance(v, int) or isinstance(v, float):\n",
    "            if v >= tree.value:\n",
    "                branch = tree.tb\n",
    "            else:\n",
    "                branch = tree.fb\n",
    "        else:\n",
    "            if v == tree.value:\n",
    "                branch = tree.tb\n",
    "            else:\n",
    "                branch = tree.fb\n",
    "        return classify(observation, branch)\n",
    "\n",
    "\n",
    "# Classify an observation with missing data\n",
    "def mdclassify(observation, tree):\n",
    "    if tree.results != None:\n",
    "        return prediction(tree.results)\n",
    "    else:\n",
    "        v = observation[tree.col]\n",
    "        if v == None:\n",
    "            tr, fr = mdclassify(observation, tree.tb), mdclassify(observation, tree.fb)\n",
    "            tcount = sum(tr.values())\n",
    "            fcount = sum(fr.values())\n",
    "            tw = float(tcount) / (tcount + fcount)\n",
    "            fw = float(fcount) / (tcount + fcount)\n",
    "            result = {}\n",
    "            for k, v in tr.items(): result[k] = v * tw\n",
    "            for k, v in fr.items(): result[k] = v * fw\n",
    "            return result\n",
    "        else:\n",
    "            if isinstance(v, int) or isinstance(v, float):\n",
    "                if v >= tree.value:\n",
    "                    branch = tree.tb\n",
    "                else:\n",
    "                    branch = tree.fb\n",
    "            else:\n",
    "                if v == tree.value:\n",
    "                    branch = tree.tb\n",
    "                else:\n",
    "                    branch = tree.fb\n",
    "            return mdclassify(observation, branch)\n",
    "\n",
    "def max_depth(tree):\n",
    "    if tree.results != None:\n",
    "        return 0\n",
    "    else:\n",
    "        # Compute the depth of each subtree\n",
    "        tDepth = max_depth(tree.tb)\n",
    "        fDepth = max_depth(tree.fb)\n",
    "\n",
    "        # Use the larger one\n",
    "        if (tDepth > fDepth):\n",
    "            return tDepth + 1\n",
    "        else:\n",
    "            return fDepth + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset to numeric\n",
    "\n",
    "The dataset for this lab contains about 450 anonymized student evaluations collected at the University of Texas at Austin, and used in the following publication: __\"Beauty in the Classroom: Instructors' Pulchritude and Putative Pedagogical Productivity\"__. You can learn how the data was collected and the meaning of various data attributes following this [link](https://chance.amstat.org/2013/04/looking-good/).\n",
    "\n",
    "We use a subset of attributes: 'rank', 'ethnicity', 'gender', 'language', 'age', 'class_size', 'class_level',  'avg_beauty_score',  and 'professor_evaluation_score' and try to predict course evaluation score. \n",
    "\n",
    "This smaller dataset can be downloaded from [here](https://drive.google.com/file/d/18wV59AYCVCqL1BIDBYLpL73emp7h8d0T/view?usp=sharing). Download the dataset into your data directory, and update the path to your file in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../../Datasets/StudentEvaluations.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the dataset into a data frame _df_. First, we will make all attributes numeric, and then we will convert all attributes to categorical labels. The _df_ points to the original dataset. We are going to create two copies: _df_num_ and _df_cat_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rank', 'ethnicity', 'gender', 'language', 'age', 'cls_students',\n",
      "       'cls_level', 'bty_avg', 'prof_eval', 'course_eval'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           rank     ethnicity  gender language  age  cls_students cls_level  \\\n",
      "0  tenure track      minority  female  english   36            43     upper   \n",
      "1  tenure track      minority  female  english   36           125     upper   \n",
      "2  tenure track      minority  female  english   36           125     upper   \n",
      "3  tenure track      minority  female  english   36           123     upper   \n",
      "4       tenured  not minority    male  english   59            20     upper   \n",
      "5       tenured  not minority    male  english   59            40     upper   \n",
      "6       tenured  not minority    male  english   59            44     upper   \n",
      "\n",
      "   bty_avg  prof_eval  course_eval  \n",
      "0      5.0        4.7          4.3  \n",
      "1      5.0        4.1          3.7  \n",
      "2      5.0        3.9          3.6  \n",
      "3      5.0        4.8          4.4  \n",
      "4      3.0        4.6          4.5  \n",
      "5      3.0        4.3          4.0  \n",
      "6      3.0        2.8          2.1  \n"
     ]
    }
   ],
   "source": [
    "print(df[:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that not all attributes are numeric. Let's make them all numeric by using the pandas _replace_ method (see [this post](https://www.geeksforgeeks.org/how-to-convert-categorical-variable-to-numeric-in-pandas/)), which replaces the original values with the predefined set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create a copy of the original data frame\n",
    "df_num = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to replace 'rank', 'ethnicity', 'gender', 'language', and 'cls_level' columns.\n",
    "Let's find out what are the values in each column - to know what to replace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tenure track', 'tenured', 'teaching'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank\n",
    "df_num['rank'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['minority', 'not minority'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ethnicity\n",
    "df_num['ethnicity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['female', 'male'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gender\n",
    "df_num['gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['english', 'non-english'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Language\n",
    "df_num['language'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['upper', 'lower'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class level\n",
    "df_num['cls_level'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning a numeric code to each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num['rank'].replace(['tenure track', 'tenured', 'teaching'], [1, 2, 3], inplace=True)\n",
    "df_num['ethnicity'].replace(['minority', 'not minority'], [1, 0], inplace=True)\n",
    "df_num['gender'].replace(['female', 'male'], [1, 2], inplace=True)\n",
    "df_num['language'].replace(['english', 'non-english'], [1, 0], inplace=True)\n",
    "df_num['cls_level'].replace(['upper', 'lower'], [2,1], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the class label an integer by rounding course evaluation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num['course_eval'] = df_num['course_eval'].round(0).astype(int)\n",
    "\n",
    "df_num['course_eval'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And check what it looks like now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>language</th>\n",
       "      <th>age</th>\n",
       "      <th>cls_students</th>\n",
       "      <th>cls_level</th>\n",
       "      <th>bty_avg</th>\n",
       "      <th>prof_eval</th>\n",
       "      <th>course_eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>125</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>125</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank  ethnicity  gender  language  age  cls_students  cls_level  bty_avg  \\\n",
       "0     1          1       1         1   36            43          2      5.0   \n",
       "1     1          1       1         1   36           125          2      5.0   \n",
       "2     1          1       1         1   36           125          2      5.0   \n",
       "3     1          1       1         1   36           123          2      5.0   \n",
       "4     2          0       2         1   59            20          2      3.0   \n",
       "5     2          0       2         1   59            40          2      3.0   \n",
       "6     2          0       2         1   59            44          2      3.0   \n",
       "\n",
       "   prof_eval  course_eval  \n",
       "0        4.7            4  \n",
       "1        4.1            4  \n",
       "2        3.9            4  \n",
       "3        4.8            4  \n",
       "4        4.6            4  \n",
       "5        4.3            4  \n",
       "6        2.8            2  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore if there is any correlation between course score and any other attributes in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "corr = df_num.corr()\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Decision Tree: numeric dataset\n",
    "### 3.1. Using custom ID3 algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_rows = df_num.to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = df_num.columns.to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would be a regression tree, as we are trying to predict a numeric score. We have to use __variance__ as a measure of node purity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = buildtree(data_rows, score_func=variance, min_improvement=0, min_samples=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prof_eval: >=3.8? \n",
      "  T->prof_eval: >=4.8? \n",
      "    T->cls_students: >=39.0? \n",
      "      T->rank: >=2.0? \n",
      "        T->age: >=62.0? \n",
      "          T->{5.0: '100%'}\n",
      "          F->cls_students: >=68.0? \n",
      "            T->cls_students: >=537.0? \n",
      "              T->cls_students: >=581.0? \n",
      "                T->{5.0: '100%'}\n",
      "                F->cls_students: >=574.0? \n",
      "                  T->cls_students: >=579.0? \n",
      "                    T->{4.0: '100%'}\n",
      "                    F->{5.0: '100%'}\n",
      "                  F->{4.0: '100%'}\n",
      "              F->{5.0: '100%'}\n",
      "            F->rank: >=3.0? \n",
      "              T->{5.0: '100%'}\n",
      "              F->{4.0: '100%'}\n",
      "        F->{4.0: '100%'}\n",
      "      F->age: >=60.0? \n",
      "        T->age: >=64.0? \n",
      "          T->{5.0: '100%'}\n",
      "          F->cls_students: >=34.0? \n",
      "            T->{5.0: '100%'}\n",
      "            F->{4.0: '100%'}\n",
      "        F->gender: >=2.0? \n",
      "          T->{5.0: '100%'}\n",
      "          F->cls_level: >=2.0? \n",
      "            T->rank: >=2.0? \n",
      "              T->cls_students: >=25.0? \n",
      "                T->{4.0: '100%'}\n",
      "                F->{5.0: '100%'}\n",
      "              F->cls_students: >=14.0? \n",
      "                T->cls_students: >=26.0? \n",
      "                  T->{5.0: '100%'}\n",
      "                  F->{4.0: '100%'}\n",
      "                F->{5.0: '100%'}\n",
      "            F->{5.0: '100%'}\n",
      "    F->prof_eval: >=4.6? \n",
      "      T->cls_students: >=27.0? \n",
      "        T->prof_eval: >=4.7? \n",
      "          T->cls_students: >=38.0? \n",
      "            T->cls_level: >=2.0? \n",
      "              T->{4.0: '100%'}\n",
      "              F->age: >=60.0? \n",
      "                T->{4.0: '100%'}\n",
      "                F->{5.0: '100%'}\n",
      "            F->rank: >=3.0? \n",
      "              T->{4.0: '100%'}\n",
      "              F->{5.0: '100%'}\n",
      "          F->{4.0: '100%'}\n",
      "        F->cls_students: >=19.0? \n",
      "          T->age: >=39.0? \n",
      "            T->age: >=59.0? \n",
      "              T->{4.0: '100%'}\n",
      "              F->{5.0: '100%'}\n",
      "            F->{4.0: '100%'}\n",
      "          F->rank: >=2.0? \n",
      "            T->bty_avg: >=3.667? \n",
      "              T->prof_eval: >=4.7? \n",
      "                T->{4.0: '100%'}\n",
      "                F->cls_students: >=17.0? \n",
      "                  T->{5.0: '100%'}\n",
      "                  F->gender: >=2.0? \n",
      "                    T->cls_students: >=14.0? \n",
      "                      T->{4.0: '100%'}\n",
      "                      F->{5.0: '100%'}\n",
      "                    F->{4.0: '100%'}\n",
      "              F->{4.0: '100%'}\n",
      "            F->prof_eval: >=4.7? \n",
      "              T->{5.0: '100%'}\n",
      "              F->gender: >=2.0? \n",
      "                T->cls_students: >=14.0? \n",
      "                  T->{5.0: '100%'}\n",
      "                  F->{4.0: '100%'}\n",
      "                F->{4.0: '100%'}\n",
      "      F->age: >=73.0? \n",
      "        T->cls_students: >=17.0? \n",
      "          T->{5.0: '100%'}\n",
      "          F->{4.0: '100%'}\n",
      "        F->prof_eval: >=3.9? \n",
      "          T->language: >=1.0? \n",
      "            T->cls_students: >=15.0? \n",
      "              T->age: >=33.0? \n",
      "                T->bty_avg: >=6.332999999999999? \n",
      "                  T->bty_avg: >=6.5? \n",
      "                    T->{4.0: '100%'}\n",
      "                    F->cls_students: >=78.0? \n",
      "                      T->{4.0: '100%'}\n",
      "                      F->{5.0: '100%'}\n",
      "                  F->prof_eval: >=4.0? \n",
      "                    T->{4.0: '100%'}\n",
      "                    F->bty_avg: >=4.833? \n",
      "                      T->cls_students: >=62.0? \n",
      "                        T->{4.0: '100%'}\n",
      "                        F->{3.0: '100%'}\n",
      "                      F->{4.0: '100%'}\n",
      "                F->cls_students: >=22.0? \n",
      "                  T->{4.0: '100%'}\n",
      "                  F->{3.0: '100%'}\n",
      "              F->age: >=43.0? \n",
      "                T->{4.0: '100%'}\n",
      "                F->prof_eval: >=4.4? \n",
      "                  T->{5.0: '100%'}\n",
      "                  F->{4.0: '100%'}\n",
      "            F->cls_students: >=66.0? \n",
      "              T->{3.0: '100%'}\n",
      "              F->{4.0: '100%'}\n",
      "          F->cls_students: >=11.0? \n",
      "            T->bty_avg: >=2.333? \n",
      "              T->ethnicity: >=1.0? \n",
      "                T->age: >=52.0? \n",
      "                  T->{4.0: '100%'}\n",
      "                  F->cls_students: >=16.0? \n",
      "                    T->{3.0: '100%'}\n",
      "                    F->{4.0: '100%'}\n",
      "                F->{4.0: '100%'}\n",
      "              F->{3.0: '100%'}\n",
      "            F->{3.0: '100%'}\n",
      "  F->prof_eval: >=3.5? \n",
      "    T->age: >=50.0? \n",
      "      T->age: >=70.0? \n",
      "        T->{3.0: '100%'}\n",
      "        F->cls_students: >=122.0? \n",
      "          T->cls_students: >=184.0? \n",
      "            T->{4.0: '100%'}\n",
      "            F->{3.0: '100%'}\n",
      "          F->cls_students: >=47.0? \n",
      "            T->{4.0: '100%'}\n",
      "            F->age: >=58.0? \n",
      "              T->{4.0: '100%'}\n",
      "              F->cls_students: >=18.0? \n",
      "                T->ethnicity: >=1.0? \n",
      "                  T->{4.0: '100%'}\n",
      "                  F->rank: >=3.0? \n",
      "                    T->cls_students: >=21.0? \n",
      "                      T->cls_students: >=22.0? \n",
      "                        T->cls_students: >=36.0? \n",
      "                          T->{4.0: '100%'}\n",
      "                          F->age: >=57.0? \n",
      "                            T->cls_students: >=28.0? \n",
      "                              T->{3.0: '100%'}\n",
      "                              F->{4.0: '100%'}\n",
      "                            F->{3.0: '100%'}\n",
      "                        F->{4.0: '100%'}\n",
      "                      F->{3.0: '100%'}\n",
      "                    F->{3.0: '100%'}\n",
      "                F->{4.0: '100%'}\n",
      "      F->bty_avg: >=7.0? \n",
      "        T->{4.0: '100%'}\n",
      "        F->cls_students: >=103.0? \n",
      "          T->{4.0: '100%'}\n",
      "          F->rank: >=3.0? \n",
      "            T->gender: >=2.0? \n",
      "              T->{4.0: '100%'}\n",
      "              F->{3.0: '100%'}\n",
      "            F->age: >=49.0? \n",
      "              T->cls_students: >=29.0? \n",
      "                T->{3.0: '100%'}\n",
      "                F->{4.0: '100%'}\n",
      "              F->{3.0: '100%'}\n",
      "    F->prof_eval: >=2.7? \n",
      "      T->cls_students: >=22.0? \n",
      "        T->prof_eval: >=2.9? \n",
      "          T->{3.0: '100%'}\n",
      "          F->cls_level: >=2.0? \n",
      "            T->age: >=64.0? \n",
      "              T->{3.0: '100%'}\n",
      "              F->{2.0: '100%'}\n",
      "            F->{3.0: '100%'}\n",
      "        F->cls_level: >=2.0? \n",
      "          T->age: >=47.0? \n",
      "            T->{3.0: '100%'}\n",
      "            F->age: >=37.0? \n",
      "              T->{4.0: '100%'}\n",
      "              F->{3.0: '100%'}\n",
      "          F->{4.0: '100%'}\n",
      "      F->gender: >=2.0? \n",
      "        T->cls_students: >=32.0? \n",
      "          T->{2.0: '100%'}\n",
      "          F->{3.0: '100%'}\n",
      "        F->{2.0: '100%'}\n"
     ]
    }
   ],
   "source": [
    "print_tree(tree, '', columns_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Using sklearn library\n",
    "The decision tree algorithm in sklearn library is not implemented very well. It requires all the attributes to be numeric - while decision trees work best with the categorical attributes. Nevertheless, we will try to run it and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class label has to be binary. So we are going to replace the 'course_eval' column with 3 bins, corresponding to the score:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide dataset into features and class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rank', 'ethnicity', 'gender', 'language', 'age', 'cls_students',\n",
      "       'cls_level', 'bty_avg', 'prof_eval'],\n",
      "      dtype='object')\n",
      "Index(['course_eval'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X = df_num.loc[:, df_num.columns != 'course_eval']\n",
    "print(X.columns)\n",
    "\n",
    "Y = df_num.loc[:, df_num.columns == 'course_eval']\n",
    "print(Y.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset intro training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different parameters can be specified to build the model:\n",
    "\n",
    "`model = tree.DecisionTreeClassifier(\n",
    "        criterion='entropy', \n",
    "        max_depth=None, \n",
    "        min_samples_split=2, \n",
    "        min_samples_leaf=1, \n",
    "        max_features=None, \n",
    "        random_state=None, \n",
    "        min_density=None, \n",
    "        compute_importances=None, \n",
    "        max_leaf_nodes=None)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=7)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier(criterion='entropy', max_depth = 7)\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- prof_eval <= 3.75\n",
      "|   |--- prof_eval <= 3.45\n",
      "|   |   |--- prof_eval <= 2.60\n",
      "|   |   |   |--- class: 2\n",
      "|   |   |--- prof_eval >  2.60\n",
      "|   |   |   |--- bty_avg <= 5.83\n",
      "|   |   |   |   |--- class: 3\n",
      "|   |   |   |--- bty_avg >  5.83\n",
      "|   |   |   |   |--- cls_students <= 22.50\n",
      "|   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |--- cls_students >  22.50\n",
      "|   |   |   |   |   |--- class: 3\n",
      "|   |--- prof_eval >  3.45\n",
      "|   |   |--- age <= 48.00\n",
      "|   |   |   |--- bty_avg <= 7.25\n",
      "|   |   |   |   |--- rank <= 1.50\n",
      "|   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |--- rank >  1.50\n",
      "|   |   |   |   |   |--- cls_students <= 33.00\n",
      "|   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |--- cls_students >  33.00\n",
      "|   |   |   |   |   |   |--- cls_students <= 57.00\n",
      "|   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- cls_students >  57.00\n",
      "|   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |--- bty_avg >  7.25\n",
      "|   |   |   |   |--- class: 4\n",
      "|   |   |--- age >  48.00\n",
      "|   |   |   |--- cls_students <= 110.00\n",
      "|   |   |   |   |--- cls_students <= 45.50\n",
      "|   |   |   |   |   |--- language <= 0.50\n",
      "|   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |--- language >  0.50\n",
      "|   |   |   |   |   |   |--- age <= 57.50\n",
      "|   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- age >  57.50\n",
      "|   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |--- cls_students >  45.50\n",
      "|   |   |   |   |   |--- class: 4\n",
      "|   |   |   |--- cls_students >  110.00\n",
      "|   |   |   |   |--- cls_students <= 174.00\n",
      "|   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |--- cls_students >  174.00\n",
      "|   |   |   |   |   |--- class: 4\n",
      "|--- prof_eval >  3.75\n",
      "|   |--- prof_eval <= 4.55\n",
      "|   |   |--- cls_students <= 20.50\n",
      "|   |   |   |--- prof_eval <= 4.25\n",
      "|   |   |   |   |--- cls_students <= 10.50\n",
      "|   |   |   |   |   |--- rank <= 2.00\n",
      "|   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |--- rank >  2.00\n",
      "|   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |--- cls_students >  10.50\n",
      "|   |   |   |   |   |--- class: 4\n",
      "|   |   |   |--- prof_eval >  4.25\n",
      "|   |   |   |   |--- age <= 68.00\n",
      "|   |   |   |   |   |--- age <= 42.50\n",
      "|   |   |   |   |   |   |--- age <= 41.00\n",
      "|   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- age >  41.00\n",
      "|   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |--- age >  42.50\n",
      "|   |   |   |   |   |   |--- bty_avg <= 5.92\n",
      "|   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- bty_avg >  5.92\n",
      "|   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |--- age >  68.00\n",
      "|   |   |   |   |   |--- class: 5\n",
      "|   |   |--- cls_students >  20.50\n",
      "|   |   |   |--- rank <= 1.50\n",
      "|   |   |   |   |--- cls_students <= 82.50\n",
      "|   |   |   |   |   |--- cls_students <= 55.00\n",
      "|   |   |   |   |   |   |--- bty_avg <= 5.83\n",
      "|   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- bty_avg >  5.83\n",
      "|   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |--- cls_students >  55.00\n",
      "|   |   |   |   |   |   |--- cls_students <= 70.00\n",
      "|   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- cls_students >  70.00\n",
      "|   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |--- cls_students >  82.50\n",
      "|   |   |   |   |   |--- class: 4\n",
      "|   |   |   |--- rank >  1.50\n",
      "|   |   |   |   |--- class: 4\n",
      "|   |--- prof_eval >  4.55\n",
      "|   |   |--- cls_students <= 36.50\n",
      "|   |   |   |--- age <= 60.50\n",
      "|   |   |   |   |--- ethnicity <= 0.50\n",
      "|   |   |   |   |   |--- prof_eval <= 4.65\n",
      "|   |   |   |   |   |   |--- bty_avg <= 6.25\n",
      "|   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- bty_avg >  6.25\n",
      "|   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |--- prof_eval >  4.65\n",
      "|   |   |   |   |   |   |--- bty_avg <= 3.58\n",
      "|   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |--- bty_avg >  3.58\n",
      "|   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |--- ethnicity >  0.50\n",
      "|   |   |   |   |   |--- class: 5\n",
      "|   |   |   |--- age >  60.50\n",
      "|   |   |   |   |--- class: 4\n",
      "|   |   |--- cls_students >  36.50\n",
      "|   |   |   |--- prof_eval <= 4.75\n",
      "|   |   |   |   |--- class: 4\n",
      "|   |   |   |--- prof_eval >  4.75\n",
      "|   |   |   |   |--- cls_students <= 197.50\n",
      "|   |   |   |   |   |--- rank <= 2.50\n",
      "|   |   |   |   |   |   |--- cls_students <= 73.50\n",
      "|   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- cls_students >  73.50\n",
      "|   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |--- rank >  2.50\n",
      "|   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |--- cls_students >  197.50\n",
      "|   |   |   |   |   |--- class: 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_list = df_num.columns.to_numpy().tolist()\n",
    "from sklearn.tree import export_text\n",
    "r = export_text(model, feature_names=columns_list[:-1])\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Categorical dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to replace all the numeric columns in _df_ by categorical labels, using [Pandas _cut_ method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html).\n",
    "\n",
    "First we create a copy of the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rank', 'ethnicity', 'gender', 'language', 'age', 'cls_students',\n",
      "       'cls_level', 'bty_avg', 'prof_eval', 'course_eval'],\n",
      "      dtype='object')\n",
      "           rank     ethnicity  gender language  age  cls_students cls_level  \\\n",
      "0  tenure track      minority  female  english   36            43     upper   \n",
      "1  tenure track      minority  female  english   36           125     upper   \n",
      "2  tenure track      minority  female  english   36           125     upper   \n",
      "3  tenure track      minority  female  english   36           123     upper   \n",
      "4       tenured  not minority    male  english   59            20     upper   \n",
      "\n",
      "   bty_avg  prof_eval  course_eval  \n",
      "0      5.0        4.7          4.3  \n",
      "1      5.0        4.1          3.7  \n",
      "2      5.0        3.9          3.6  \n",
      "3      5.0        4.8          4.4  \n",
      "4      3.0        4.6          4.5  \n"
     ]
    }
   ],
   "source": [
    "print(df_cat.columns)\n",
    "print(df_cat[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to bin columns 'age', 'cls_students', 'bty_avg', 'prof_eval', and 'course_eval'. Everything else is already categorical.\n",
    "\n",
    "First thing is to determine the domain for each numeric column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: 29 to 73\n"
     ]
    }
   ],
   "source": [
    "# Age\n",
    "age_column = df_cat[\"age\"]\n",
    "print(\"From:\", age_column.min(), \"to\", age_column.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: 1.6669999999999998 to 8.167\n"
     ]
    }
   ],
   "source": [
    "# Beauty score\n",
    "bty_ave_column = df_cat[\"bty_avg\"]\n",
    "print(\"From:\", bty_ave_column.min(), \"to\", bty_ave_column.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: 8 to 581\n"
     ]
    }
   ],
   "source": [
    "# Class size\n",
    "num_students_column = df_cat[\"cls_students\"]\n",
    "print(\"From:\", num_students_column.min(), \"to\", num_students_column.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: 2.3 to 5.0\n"
     ]
    }
   ],
   "source": [
    "# Professor score\n",
    "prof_eval_column = df_cat[\"prof_eval\"]\n",
    "print(\"From:\", prof_eval_column.min(), \"to\", prof_eval_column.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: 2.1 to 5.0\n"
     ]
    }
   ],
   "source": [
    "# Course score (class label)\n",
    "course_eval_column = df_cat[\"course_eval\"]\n",
    "print(\"From:\", course_eval_column.min(), \"to\", course_eval_column.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Age to bins\n",
    "bins = [20, 35, 50, 65, np.inf]\n",
    "names = [ '20-35', '35-50',  '50-65', '65+']\n",
    "\n",
    "df_cat['age'] = pd.cut(df_cat['age'], bins, labels=names)\n",
    "\n",
    "# Class size to bins\n",
    "bins = [0, 15, 30, 50, 100, np.inf]\n",
    "names = [ '<15', '15-30',  '30-50', '50-100', '100+']\n",
    "\n",
    "df_cat['cls_students'] = pd.cut(df_cat['cls_students'], bins, labels=names)\n",
    "\n",
    "# Beauty average to bins\n",
    "bins = [0, 3, 6, 9, np.inf]\n",
    "names = [ '<3', '3-6',  '6-9', '9+']\n",
    "\n",
    "df_cat['bty_avg'] = pd.cut(df_cat['bty_avg'], bins, labels=names)\n",
    "\n",
    "# Professor score to bins\n",
    "bins = [0, 2, 3, 4, 4.5, np.inf]\n",
    "names = [ '<2', '2-3',  '3-4', '4-4.5', '4.5+']\n",
    "\n",
    "df_cat['prof_eval'] = pd.cut(df_cat['prof_eval'], bins, labels=names)\n",
    "\n",
    "# Course score to class label\n",
    "bins = [0, 2, 3, 4, 4.5, np.inf]\n",
    "names = [ 'bad', 'fair',  'average', 'good', 'excellent']\n",
    "\n",
    "df_cat['course_eval'] = pd.cut(df_cat['course_eval'], bins, labels=names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rank', 'ethnicity', 'gender', 'language', 'age', 'cls_students',\n",
      "       'cls_level', 'bty_avg', 'prof_eval', 'course_eval'],\n",
      "      dtype='object')\n",
      "           rank     ethnicity  gender language    age cls_students cls_level  \\\n",
      "0  tenure track      minority  female  english  35-50        30-50     upper   \n",
      "1  tenure track      minority  female  english  35-50         100+     upper   \n",
      "2  tenure track      minority  female  english  35-50         100+     upper   \n",
      "3  tenure track      minority  female  english  35-50         100+     upper   \n",
      "4       tenured  not minority    male  english  50-65        15-30     upper   \n",
      "\n",
      "  bty_avg prof_eval course_eval  \n",
      "0     3-6      4.5+        good  \n",
      "1     3-6     4-4.5     average  \n",
      "2     3-6       3-4     average  \n",
      "3     3-6      4.5+        good  \n",
      "4      <3      4.5+        good  \n"
     ]
    }
   ],
   "source": [
    "print(df_cat.columns)\n",
    "print(df_cat[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Decision Tree: categorical dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_rows = df_cat.to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = df_cat.columns.to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this is a decision tree (classification), we use entropy as a measure of leaf purity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = buildtree(data_rows, score_func=entropy, min_improvement=0, min_samples=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prof_eval: 4.5+? \n",
      "  T->cls_students: 15-30? \n",
      "    T->bty_avg: <3? \n",
      "      T->{'good': '100%'}\n",
      "      F->cls_level: lower? \n",
      "        T->ethnicity: not minority? \n",
      "          T->rank: tenured? \n",
      "            T->gender: female? \n",
      "              T->{'excellent': '100%'}\n",
      "              F->age: 50-65? \n",
      "                T->{'good': '100%'}\n",
      "                F->{'excellent': '100%'}\n",
      "            F->gender: female? \n",
      "              T->bty_avg: 6-9? \n",
      "                T->{'good': '50%', 'excellent': '50%'}\n",
      "                F->{'excellent': '100%'}\n",
      "              F->{'excellent': '100%'}\n",
      "          F->{'excellent': '100%'}\n",
      "        F->bty_avg: 6-9? \n",
      "          T->{'excellent': '100%'}\n",
      "          F->ethnicity: not minority? \n",
      "            T->{'excellent': '50%', 'good': '50%'}\n",
      "            F->{'excellent': '100%'}\n",
      "    F->cls_students: <15? \n",
      "      T->rank: tenured? \n",
      "        T->gender: male? \n",
      "          T->bty_avg: <3? \n",
      "            T->age: 50-65? \n",
      "              T->cls_level: lower? \n",
      "                T->{'excellent': '100%'}\n",
      "                F->{'good': '66%', 'excellent': '33%'}\n",
      "              F->{'excellent': '100%'}\n",
      "            F->cls_level: upper? \n",
      "              T->{'excellent': '50%', 'good': '50%'}\n",
      "              F->{'good': '100%'}\n",
      "          F->{'excellent': '100%'}\n",
      "        F->gender: female? \n",
      "          T->rank: tenure track? \n",
      "            T->{'excellent': '60%', 'good': '40%'}\n",
      "            F->{'good': '100%'}\n",
      "          F->rank: tenure track? \n",
      "            T->cls_level: lower? \n",
      "              T->{'good': '50%', 'excellent': '50%'}\n",
      "              F->{'excellent': '100%'}\n",
      "            F->{'excellent': '100%'}\n",
      "      F->age: 50-65? \n",
      "        T->cls_students: 100+? \n",
      "          T->cls_level: lower? \n",
      "            T->{'excellent': '60%', 'good': '40%'}\n",
      "            F->{'good': '50%', 'excellent': '50%'}\n",
      "          F->cls_students: 50-100? \n",
      "            T->{'good': '100%'}\n",
      "            F->rank: teaching? \n",
      "              T->{'excellent': '100%'}\n",
      "              F->cls_level: lower? \n",
      "                T->{'good': '100%'}\n",
      "                F->bty_avg: 3-6? \n",
      "                  T->{'excellent': '33%', 'good': '66%'}\n",
      "                  F->{'good': '100%'}\n",
      "        F->cls_students: 100+? \n",
      "          T->{'good': '100%'}\n",
      "          F->age: 65+? \n",
      "            T->{'average': '100%'}\n",
      "            F->cls_level: lower? \n",
      "              T->{'excellent': '100%'}\n",
      "              F->cls_students: 50-100? \n",
      "                T->rank: tenure track? \n",
      "                  T->{'good': '100%'}\n",
      "                  F->{'good': '60%', 'excellent': '40%'}\n",
      "                F->gender: female? \n",
      "                  T->bty_avg: 6-9? \n",
      "                    T->{'good': '75%', 'average': '25%'}\n",
      "                    F->rank: tenure track? \n",
      "                      T->ethnicity: minority? \n",
      "                        T->{'good': '100%'}\n",
      "                        F->{'excellent': '33%', 'good': '66%'}\n",
      "                      F->{'good': '33%', 'average': '33%', 'excellent': '33%'}\n",
      "                  F->rank: tenure track? \n",
      "                    T->{'excellent': '100%'}\n",
      "                    F->{'good': '100%'}\n",
      "  F->prof_eval: 4-4.5? \n",
      "    T->cls_students: <15? \n",
      "      T->rank: tenured? \n",
      "        T->age: 65+? \n",
      "          T->{'good': '100%'}\n",
      "          F->cls_level: upper? \n",
      "            T->bty_avg: 3-6? \n",
      "              T->{'good': '100%'}\n",
      "              F->age: 50-65? \n",
      "                T->{'good': '80%', 'average': '20%'}\n",
      "                F->{'average': '100%'}\n",
      "            F->bty_avg: 3-6? \n",
      "              T->age: 50-65? \n",
      "                T->{'average': '100%'}\n",
      "                F->gender: female? \n",
      "                  T->{'average': '50%', 'good': '50%'}\n",
      "                  F->{'good': '100%'}\n",
      "              F->{'good': '100%'}\n",
      "        F->gender: female? \n",
      "          T->{'good': '100%'}\n",
      "          F->rank: tenure track? \n",
      "            T->cls_level: lower? \n",
      "              T->{'good': '100%'}\n",
      "              F->{'excellent': '66%', 'good': '33%'}\n",
      "            F->{'good': '100%'}\n",
      "      F->age: 65+? \n",
      "        T->cls_students: 15-30? \n",
      "          T->{'excellent': '100%'}\n",
      "          F->{'average': '100%'}\n",
      "        F->age: 50-65? \n",
      "          T->bty_avg: 6-9? \n",
      "            T->ethnicity: minority? \n",
      "              T->{'average': '50%', 'good': '50%'}\n",
      "              F->{'excellent': '100%'}\n",
      "            F->ethnicity: minority? \n",
      "              T->{'average': '100%'}\n",
      "              F->cls_students: 15-30? \n",
      "                T->rank: tenure track? \n",
      "                  T->{'good': '50%', 'average': '50%'}\n",
      "                  F->bty_avg: 3-6? \n",
      "                    T->{'good': '100%'}\n",
      "                    F->cls_level: lower? \n",
      "                      T->{'good': '100%'}\n",
      "                      F->{'average': '100%'}\n",
      "                F->cls_level: lower? \n",
      "                  T->{'average': '100%'}\n",
      "                  F->cls_students: 30-50? \n",
      "                    T->rank: teaching? \n",
      "                      T->gender: female? \n",
      "                        T->bty_avg: 3-6? \n",
      "                          T->{'average': '50%', 'good': '50%'}\n",
      "                          F->{'average': '33%', 'good': '66%'}\n",
      "                        F->{'average': '100%'}\n",
      "                      F->bty_avg: 3-6? \n",
      "                        T->{'good': '80%', 'average': '20%'}\n",
      "                        F->{'average': '50%', 'good': '50%'}\n",
      "                    F->rank: teaching? \n",
      "                      T->{'good': '100%'}\n",
      "                      F->cls_students: 100+? \n",
      "                        T->{'good': '71%', 'average': '28%'}\n",
      "                        F->{'average': '37%', 'good': '62%'}\n",
      "          F->gender: male? \n",
      "            T->rank: tenure track? \n",
      "              T->cls_students: 15-30? \n",
      "                T->age: 20-35? \n",
      "                  T->bty_avg: 6-9? \n",
      "                    T->{'average': '100%'}\n",
      "                    F->ethnicity: minority? \n",
      "                      T->{'average': '100%'}\n",
      "                      F->{'good': '100%'}\n",
      "                  F->{'good': '100%'}\n",
      "                F->{'good': '100%'}\n",
      "              F->ethnicity: minority? \n",
      "                T->{'good': '100%'}\n",
      "                F->age: 35-50? \n",
      "                  T->cls_students: 15-30? \n",
      "                    T->cls_level: lower? \n",
      "                      T->{'average': '100%'}\n",
      "                      F->bty_avg: 6-9? \n",
      "                        T->{'good': '100%'}\n",
      "                        F->rank: teaching? \n",
      "                          T->{'average': '40%', 'good': '60%'}\n",
      "                          F->{'average': '33%', 'good': '66%'}\n",
      "                    F->language: english? \n",
      "                      T->rank: teaching? \n",
      "                        T->cls_students: 100+? \n",
      "                          T->{'average': '25%', 'good': '75%'}\n",
      "                          F->{'average': '100%'}\n",
      "                        F->cls_students: 100+? \n",
      "                          T->{'average': '100%'}\n",
      "                          F->bty_avg: 3-6? \n",
      "                            T->cls_students: 30-50? \n",
      "                              T->{'average': '66%', 'good': '33%'}\n",
      "                              F->cls_level: lower? \n",
      "                                T->{'average': '66%', 'good': '33%'}\n",
      "                                F->{'average': '100%'}\n",
      "                            F->{'average': '100%'}\n",
      "                      F->{'good': '100%'}\n",
      "                  F->{'good': '100%'}\n",
      "            F->cls_level: lower? \n",
      "              T->cls_students: 15-30? \n",
      "                T->rank: tenure track? \n",
      "                  T->{'average': '66%', 'good': '33%'}\n",
      "                  F->{'average': '100%'}\n",
      "                F->age: 20-35? \n",
      "                  T->{'average': '100%'}\n",
      "                  F->bty_avg: 3-6? \n",
      "                    T->rank: teaching? \n",
      "                      T->{'average': '100%'}\n",
      "                      F->cls_students: 50-100? \n",
      "                        T->{'average': '100%'}\n",
      "                        F->{'good': '100%'}\n",
      "                    F->{'good': '100%'}\n",
      "              F->rank: tenured? \n",
      "                T->bty_avg: 3-6? \n",
      "                  T->{'good': '50%', 'average': '50%'}\n",
      "                  F->{'average': '100%'}\n",
      "                F->bty_avg: 6-9? \n",
      "                  T->cls_students: 50-100? \n",
      "                    T->{'good': '100%'}\n",
      "                    F->{'average': '100%'}\n",
      "                  F->cls_students: 30-50? \n",
      "                    T->bty_avg: 3-6? \n",
      "                      T->{'average': '83%', 'good': '16%'}\n",
      "                      F->{'average': '100%'}\n",
      "                    F->{'average': '100%'}\n",
      "    F->prof_eval: 3-4? \n",
      "      T->ethnicity: minority? \n",
      "        T->cls_students: 30-50? \n",
      "          T->rank: tenure track? \n",
      "            T->{'fair': '100%'}\n",
      "            F->{'average': '100%'}\n",
      "          F->bty_avg: 6-9? \n",
      "            T->age: 35-50? \n",
      "              T->cls_students: 50-100? \n",
      "                T->{'average': '100%'}\n",
      "                F->{'good': '100%'}\n",
      "              F->{'average': '100%'}\n",
      "            F->{'average': '100%'}\n",
      "        F->cls_students: <15? \n",
      "          T->rank: teaching? \n",
      "            T->{'average': '100%'}\n",
      "            F->age: 50-65? \n",
      "              T->gender: female? \n",
      "                T->{'average': '100%'}\n",
      "                F->cls_level: lower? \n",
      "                  T->{'average': '100%'}\n",
      "                  F->{'average': '66%', 'fair': '33%'}\n",
      "              F->bty_avg: 6-9? \n",
      "                T->rank: tenure track? \n",
      "                  T->{'fair': '50%', 'average': '50%'}\n",
      "                  F->{'average': '100%'}\n",
      "                F->{'fair': '100%'}\n",
      "          F->rank: tenured? \n",
      "            T->bty_avg: 3-6? \n",
      "              T->{'average': '100%'}\n",
      "              F->cls_students: 15-30? \n",
      "                T->{'average': '100%'}\n",
      "                F->age: 50-65? \n",
      "                  T->cls_students: 30-50? \n",
      "                    T->{'average': '100%'}\n",
      "                    F->cls_level: lower? \n",
      "                      T->cls_students: 100+? \n",
      "                        T->{'average': '75%', 'fair': '25%'}\n",
      "                        F->{'fair': '50%', 'average': '50%'}\n",
      "                      F->gender: female? \n",
      "                        T->{'average': '75%', 'fair': '25%'}\n",
      "                        F->{'average': '100%'}\n",
      "                  F->{'average': '100%'}\n",
      "            F->bty_avg: <3? \n",
      "              T->{'average': '100%'}\n",
      "              F->language: non-english? \n",
      "                T->{'average': '100%'}\n",
      "                F->cls_students: 100+? \n",
      "                  T->{'average': '100%'}\n",
      "                  F->cls_students: 30-50? \n",
      "                    T->cls_level: lower? \n",
      "                      T->{'fair': '100%'}\n",
      "                      F->age: 50-65? \n",
      "                        T->gender: female? \n",
      "                          T->{'average': '100%'}\n",
      "                          F->{'fair': '100%'}\n",
      "                        F->{'average': '100%'}\n",
      "                    F->bty_avg: 6-9? \n",
      "                      T->{'average': '100%'}\n",
      "                      F->gender: female? \n",
      "                        T->age: 50-65? \n",
      "                          T->{'average': '83%', 'fair': '16%'}\n",
      "                          F->cls_students: 50-100? \n",
      "                            T->{'average': '100%'}\n",
      "                            F->rank: tenure track? \n",
      "                              T->{'fair': '50%', 'average': '50%'}\n",
      "                              F->{'average': '66%', 'fair': '33%'}\n",
      "                        F->{'average': '100%'}\n",
      "      F->ethnicity: minority? \n",
      "        T->rank: tenure track? \n",
      "          T->{'fair': '66%', 'average': '33%'}\n",
      "          F->{'fair': '100%'}\n",
      "        F->{'fair': '100%'}\n"
     ]
    }
   ],
   "source": [
    "print_tree(tree, '', columns_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the best we could do for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. [TASK 1] Using learned tree for classification\n",
    "\n",
    "Recall at least 3 different courses you have taken, and record the values of the attributes, and the course score that you have given to the course. Run the predict function to see if the decision tree correctly predicts your score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Attributes with My Evaluations:\n",
    "\n",
    "| Class no. | rank | ethnicity | gender | language | age | cls_students | cls_level | bty_avg | prof_eval | My Eval |\n",
    "|---|---|---|---|---|---|---|---|---|---|---|\n",
    "| 1 | tenured | minority | male | english | 50-65 | 30-45| upper | 3-6 | 4.5+ | good |\n",
    "| 2 | tenure track | not minority | male | english | 35-50 | 15-30| upper | 3-6 | 4-4.5 | excellent |\n",
    "| 3 | tenured | not minority | male | english | 50-65 | 100+ | lower | 3-6 | 4-4.5 | average |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'excellent': '33%', 'good': '66%'}\n",
      "{'good': '100%'}\n",
      "{'average': '100%'}\n"
     ]
    }
   ],
   "source": [
    "# Class 1:\n",
    "print(classify(['tenured','minority','male','english','50-65','30-45','upper','3-6','4.5+'],tree))\n",
    "\n",
    "# Class 2:\n",
    "print(classify(['tenure track','not minority','male','english','35-50','15-30','upper','3-6','4-4.5'],tree))\n",
    "\n",
    "# Class 3:\n",
    "print(classify(['tenured','not minority','male','english','50-65','100+','lower','3-6','4-4.5'],tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted vs. Real Evaluations:\n",
    "\n",
    "| Class no. | Predicted | Real | Correct? |\n",
    "|---|---|---|---|\n",
    "| 1 | good | good | YES |\n",
    "| 2 | good | excellent | NO |\n",
    "| 3 | average | average | YES |\n",
    "\n",
    "Assuming that we select the most frequent case from the resulting leaf, th tree predicts my course evaluation correct in 2 out of 3 cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. [TASK 2] Important factors\n",
    "What are the most important attributes in separating good course evaluations from the bad ones? Support your answer by analyzing the tree levels and the leaf outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In looking at the tree results, professor evaluation seems to be the single most important attribute for predicting course scores. This is true because the first split occurs based on this attribute, suggesting that the entropy is reduced most from splitting based on this attribute. Also, in looking at the resulting leaves following a split on professor evaluation, the majority of results following a rating of 4.5 or higher fall under the 'excellent' or 'good' category.\n",
    "\n",
    "Another interesting and seemingly important attribute is ethnicity, and it seems that anytime the professor is listed as minority, there are seldom any class ratings that fall within the 'excellent' category, and 'average' and 'fair' seemed to be the most common predictions. \n",
    "\n",
    "Additionally, number of students in the class seemed to be an important predictor, and looking at the leaves on the tree, I would guess that there is a decent correlation between smaller class size and better course score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. [TASK 3] Rules\n",
    "Extract from the tree at least 3 rules that you find most reliable. Did any of these rules surprise you?\n",
    "\n",
    "### Rules:\n",
    "\n",
    "1. The simplest rule I found is the following:\n",
    "\n",
    "If professor evaluation <3 and minority, then course score is 'fair'. \n",
    "\n",
    "This rule in particular surpirsed me, because the fact that classifications are being made solely based on ethnicity for professors with low evaluation scores seems like not the best way of predicting course quality. \n",
    "\n",
    "2. This one is also simple, but follows the \"true\" branches\"\n",
    "\n",
    "If professor evaluation >4.5, class size 15-30, and beauty score <3, then coourse score is 'good'.\n",
    "\n",
    "Again, this was surprising to me that beauty score wopuld play an important role only at the third level of the tree.\n",
    "\n",
    "3. This rule is just absurd:\n",
    "\n",
    "If professor evaluation >4.5, class size <15, rank is not 'tenured', gender is female, and rank is not 'tenure track', then course score is 'good'.\n",
    "\n",
    "There is just too much going on here, and I suspect we don;'t have enough data to believe that this rule is dependable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. [BONUS] Web visualization\n",
    "The visualizations of the tree can be made much more expressive with the _d3.js_ visualization library. Sample  _public_html_ folder containing all the required html, css, and javascript files, including the library itself, is provided. \n",
    "\n",
    "In order to create this visualization, all you need is a json file which represents the nodes of the final decision tree. Learn the required JSON format, and implement this conversion in a separate file __dtree_to_json.py__. Submit your file with the lab. \n",
    "\n",
    "Copy the resulting json file into the data directory in the _public_html_ folder, and update the name of the json file in the JavaScript code on line 39 in _index.html_. \n",
    "\n",
    "Note that Chrome would not allow you to run the visualization locally - so if you want to present it to the world you should use a web server. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2020 Marina Barsky. All rights reserved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
